---
title: "ds_hw6"
author: "DITIANLI"
date: "November 25, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(broom)
library(modelr)
library(knitr)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_bw())
set.seed(1)
```

#Problem 1

Create a city_state variable, and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO, these do not report victim race. Also omit Tulsa, AL this is a data entry mistake. Modifiy victim_race to have categories white and non-white, with white as the reference category. 

```{r}
homicide <- 
  read_csv("./data/homicide-data.csv") %>% 
  janitor::clean_names()
homicide 

homicide1 <- 
  homicide %>% 
   mutate(victim_race = fct_relevel(ifelse(victim_race == "White", "white", "non-white"), "white"),
         victim_age = ifelse(victim_age == "Unknown", NA, as.integer(victim_age)),
         victim_sex = as.factor(victim_sex),
         city_state = paste(paste0(city, ","), state),
         resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")) %>% 
  select(uid, victim_race, victim_age, victim_sex, city_state, resolved)
homicide1
```

For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors.

```{r}
balt <- homicide1 %>% 
  filter(city_state == "Baltimore, MD")

fit <- glm(resolved ~ victim_age + victim_sex + victim_race, data = balt, family = binomial()) %>% 
  broom::tidy()
fit

save(fit,file = "fit_glm.RData") #Save the output of glm as an R object
```
Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed.
```{r}
fit <- fit %>% 
  mutate(OR = exp(estimate),
         CI_low = exp(estimate - std.error*1.96),
         CI_up = exp(estimate + std.error*1.96)) %>% 
  dplyr::select(term, estimate, OR, CI_low, CI_up) %>% 
    knitr::kable(digits = 2)
fit
```

Comment:The estimate OR for race is 0.44(95%CI:0.31,0.62). Interpretation: the odds of resolving the case for non-white people is 0.441 times the odds compared to white people. 


Run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. 

```{r}
city_logistic = function(x){
  
    homicide1 %>% 
    filter(city_state == x) %>% 
    glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())  %>% 
    broom::tidy() %>% 
    mutate(OR = exp(estimate),
           CI_low = exp(estimate - 1.96 * std.error),
           CI_up = exp(estimate + 1.96 * std.error)) %>% 
    filter(term == "victim_racenon-white") %>% 
    select(beta = estimate, p.value, OR, CI_low,CI_up)
}

city_result = 
  tibble(city_state = unique(homicide1$city_state)) %>% 
  mutate(map(.x = unique(homicide1$city_state), ~city_logistic(.x))) %>% 
  unnest
```

Create a plot that shows the estimated ORs and CIs for each city.
```{r}
city_result %>% 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
    geom_point() +
    geom_errorbar(aes(ymin = CI_low, ymax = CI_up)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.3, size = 8)) +
    labs(
      x = "City",
      y = "OR",
      title = "Estimated OR for Solving Homicides Comparing Non-white Victims to White Victims"
    )

```

Comment: The OR differs from state to state, but the mean odds ratio of solving for a non-white victim case compared to white victime is less than 1, which means non-white victim cases are more likely to be unsolved.
Boston has the smallest OR, Tampa has the largest OR, Durham has the largest CI.


#Problem 2
In this probelm, we analyzed data gathered to understand the effects of several variables on a childâ€™s birthweight.
```{r}
birthweight<- read_csv("./data/birthweight.csv") 

birthweight%>% 
  janitor::clean_names() %>% 
  na.omit() %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))
library(psych)
describe(birthweight)
```
Use psych package to check distributions, pnumlbw and pnumsga are all zero, and other variables do not have missing data.

```{r}
fit_full = lm(bwt ~ .,data = birthweight)
backward<-step(fit_full, direction="backward",trace = 0)

backward %>% 
  broom::tidy() %>% 
  knitr::kable(digit = 2)
```
Using backward method to select model.

```{r}
my_model = lm(bwt ~ babysex + bhead + blength + gaweeks + mheight + mrace + parity + smoken,data = birthweight)
summary(my_model)

par(mfrow = c(2,2))#check assumption
plot(my_model)
```

According to article'European Journal of Obstetrics & Gynecology and Reproductive Biology' and 'Maternal pregravid weight, age, and smoking status as risk factors for low birth weight births' and from the result of backward selection, we finally decide to choose babysex, bhead, blength, gaweeks, 
mheight, mrace, parity and smoken as predictors in our final model.
Q-Q plot is roughly linear, the assumption is not violated.

```{r}
birthweight %>% 
  add_residuals(my_model) %>% 
  add_predictions(my_model) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = 0.3) +
  labs(
     title = "Model residuals against fitted values",
     x = "Fitted values",
     y = "Residuals"
   )
```

Comment: the residuals are clusteredd, we need to revise the model.

```{r}
model1 <- lm(bwt ~ blength + gaweeks, data = birthweight)
summary(model1)
model2<- lm(bwt ~ bhead + blength + babysex + bhead*babysex + bhead*blength + blength*babysex + bhead*babysex*blength, data = birthweight)
summary(model2)

```

```{r}
cv <- birthweight %>% 
  crossv_mc(100)

cv_compare<-cv %>% 
   mutate(
     my_model = map(train, ~lm(bwt ~ babysex + bhead + blength + gaweeks + mheight + mrace + parity + smoken,data = .)), 
     model1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
     model2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*babysex + bhead*blength + blength*babysex + bhead*babysex*blength, data = .)))%>% 
   mutate(rmse_my_model = map2_dbl(my_model, test, ~rmse(.x, .y)),
         rmse_model1 = map2_dbl(model1, test, ~rmse(.x, .y)),
         rmse_model2 = map2_dbl(model2, test, ~rmse(.x, .y)))
```

```{r}
cv_compare %>% 
  dplyr::select(starts_with('rmse')) %>% 
  gather(key = model, value = rmse, rmse_my_model:rmse_model2) %>%  
  mutate(model = str_replace(model, "rmse_", "")) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  labs(
     title = "Prediction error distribution for models",
     x = "Model",
     y = "RMSE"
   )
```


Comment: Based on the RMSE, the my_model have the least mean rmse and least error variance across these three models. The first model with only parameters in linear form has the least predictive ability. The second model involving main effect of baby head circumference, body length, babysex and their interactions have better predictive capability than the first one.
